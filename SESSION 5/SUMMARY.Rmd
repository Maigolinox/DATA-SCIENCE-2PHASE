---
title: "SESSION 5 SUMMARY"
author: "Victor Miguel Terrón Macias"
date: "24/1/2021"
output: pdf_document
---

# SESION 5. REGRESION LINEAL Y CLASIFICACIÓN

## INTRODUCCIÓN

Supongamos que nuestro trabajo consiste en aconsejar a un cliente sobre cómo mejorar las ventas de un producto particular, y el conjunto de datos con el que disponemos son datos de Publicidad que consisten en las ventas de aquel producto en 200 diferentes mercados, junto con presupuestos de publicidad para el producto en cada uno de aquellos mercados para tres medios de comunicación diferentes: TV, radio, y periódico. No es posible para nuestro cliente incrementar directamente las ventas del producto. Por otro lado, ellos pueden controlar el gasto en publicidad para cada uno de los tres medios de comunicación. Por lo tanto, si determinamos que hay una asociación entre publicidad y ventas, entonces podemos instruir a nuestro cliente para que ajuste los presupuestos de publicidad, y así indirectamente incrementar las ventas. 

En otras palabras, nuestro objetivo es desarrollar un modelo preciso que pueda ser usado para predecir las ventas sobre la base de los tres presupuestos de medios de comunicación. En este contexto, los presupuestos de publicidad son las variables de entrada mientras que las ventas es una variable de salida. Las variables de entrada típicamente se denotan usando el símbolo X, con un subíndice para distinguirlas. Así X1 puede ser el presupuesto para TV, X2 el presupuesto para radio, y X3 el presupuesto para periódico. Las entradas tienen diferentes nombres, tales como predictores, variables independientes, características, o a veces solo variables. La variable de salida -en este caso, las ventas- frecuentemente es llamada la variable de respuesta o dependiente, y se denota típicamente con el símbolo Y.

<!-- ```{r instpack,comment=NA,echo=FALSE,eval=FALSE} -->
<!-- install.packages("TSA") -->
<!-- ``` -->

Más generalmente, suponga que observamos una respuesta cuantitativa Y y p diferentes predictores, X1, X2, …, Xp. Asumimos que hay alguna relación entre Y y X=(X1, X2, …, Xp), la cual podemos escribir en la forma muy general

![FORMULA](C:/Users/Victor Miguel Terron/Documents/s.png)

Aquí f es alguna función desconocida pero fija de X1, X2, …, Xp, y es un término de error aleatorio, el cual es independiente de X y tiene media cero. En esta formulación, f representa la información sistemática que X proporciona acerca de Y. Sin embargo, la función f que conecta las variables de entrada a la variable de salida en general es desconocida. En esta situación debemos estimar f basados en los datos observados. En esencia, el aprendizaje estadístico se refiere a un conjunto de enfoques para estimar f.

# ¿POR QUÉ ESTIMAR $f$?

Hay dos razones principales por las cuales podemos desear estimar f: predicción e inferencia.


## REGRESION LINEAL SIMPLE

Con frecuencia es necesario determinar si dos variables (aleatorias) están relacionadas de alguna manera. Por ejemplo, ¿tendrán los años de educación efecto sobre el salario que percibe un individuo? La relación entre dos variables cuantitativas puede visualizarse en un diagrama de dispersión en el plano, representando los valores de las variables en los ejes horizontal y vertical.

![Ejemplo de regresion lineal](C:/Users/Victor Miguel Terron/Documents/s1.png)

La correlación puede darse entre variables sin ninguna implicación de causalidad entre ellas, por ejemplo: si tomamos una muestra de individuos y medimos los diámetros del antebrazo y del muslo, seguramente encontraremos que hay una correlación positiva alta. Evidentemente no hay ninguna relación de causalidad entre estas variables y más bien ambas dependen del peso y la altura del individuo. A este tipo de correlación entre variables se le conoce como correlación espuria. La asociación más simple entre variables es cuando éstas se relacionan en forma lineal, sin embargo, no siempre es posible establecer este tipo de relación entre ellas. Para medir la magnitud de la asociación lineal entre dos variables, se utiliza comúnmente el coeficiente de correlación introducido por Karl Pearson. Éste es un número entre el -1 y el 1 denotado por la letra R. Si R = -1, se tiene una relación negativa perfecta y los puntos en el diagrama de dispersión se encuentran sobre una recta con pendiente negativa. Si R = 1, la relación lineal es también perfecta pero positiva: los puntos en el diagrama de dispersión están sobre una recta con pendiente positiva. Si R = 0, entonces no hay relación lineal alguna y los puntos forman más bien una nube difusa o algún otro patrón evidentemente no lineal. Lo usual es tener casos intermedios, en donde existe algún grado moderado de correlación lineal entre las variables. En general, en las ciencias sociales es raro tener coeficientes de correlación mayores que 0.7 (o menores que -0.7). A continuación, tenemos datos de estatura y pesos de unos individuos. Altura <- c(1.94, 1.82, 1.75, 1.80, 1.62, 1.64, 1.68, 1.46, 1.50, 1.55, 1.72, 1.67, 1.57, 1.60) Peso <- c(98, 80, 72, 83, 65, 70, 67, 47, 45, 50, 70, 61, 50, 52) Para obtener el coeficiente correlación de Pearson únicamente ejecutamos la siguiente instrucción en R cor(Altura, Peso) lo cual nos da 0.9645. A continuación, vamos a ajustar un modelo de regresión lineal simple a un conjunto de datos en R. Suponga que el conjunto de datos proviene de una fábrica que elabora productos

![tabla](C:/Users/Victor Miguel Terron/Documents/s2.png)

Para cada caso se considera un tamaño del proceso o tamaño de la ejecución (RunSize) y un tiempo del proceso o tiempo de la ejecución (RunTime). El tamaño del proceso representa la cantidad de artículos que se fabrica en un caso determinado, el tiempo del proceso representa la cantidad de minutos que toma elaborar los artículos en el caso especificado. En los datos anteriores, el primer caso indica que para elaborar 175 artículos se requirió un tiempo de 195 minutos. El segundo caso indica que para elaborar 189 artículos se tomó un tiempo de 215 minutos. El último caso indica que, para elaborar 68 artículos, se requirió un tiempo de fabricación de 172 minutos. Para comenzar a trabajar con los datos deberá guardarlos en su directorio de trabajo. A continuación, importe los datos a R mediante la siguiente instrucción production <- read.table("production.txt", header = TRUE), puede observar el conjunto de datos en R al ejecutar la palabra production. Extraiga las columnas RunSize y RunTime del data frame production mediante la instrucción attach(production), es decir, de ahora en adelante podrá utilizar los vectores RunSize y RunTime en R. Realice el gráfico de dispersión de los datos al ejecutar la siguiente instrucción plot(RunSize, RunTime, xlab="Run Size", ylab = "Run Time").

![grafica](C:/Users/Victor Miguel Terron/Documents/s3.png)

Cada punto del gráfico de dispersión representa el tamaño del proceso y el tiempo del proceso de un caso determinado. Ajuste un modelo de regresión lineal simple a los datos en R y obtenga un resumen del modelo ajustado al ejecutar las siguientes dos instrucciones # Ajuste el modelo m1 <- lm(RunTime~RunSize) summary(m1)

![Imagen1](C:/Users/Victor Miguel Terron/Documents/s4.png)


![Imagen2](C:/Users/Victor Miguel Terron/Documents/s5.png)


![Imagen3](C:/Users/Victor Miguel Terron/Documents/s6.png)


![Imagen4](C:/Users/Victor Miguel Terron/Documents/s7.png)


![Imagen5](C:/Users/Victor Miguel Terron/Documents/s8.png)



![Imagen6](C:/Users/Victor Miguel Terron/Documents/s9.png)


![Imagen7](C:/Users/Victor Miguel Terron/Documents/s10.png)


# MAQUINAS DE VECTORES DE SOPORTE

Un enfoque para clasificación que se desarrolló en la comunidad de las ciencias computacionales en los años 90 y que ha crecido en popularidad desde entonces son las máquinas de vectores de soporte (MVS o SVM por sus siglas en inglés). Las MVS han mostrado un buen desempeño en una variedad de contextos, y frecuentemente se les considera como uno de los mejores clasificadores.

## CLASIFICADOR DE MARGEN MAXIMO

Nuestro objetivo es desarrollar un clasificador basado en los datos de entrenamiento que clasificará una observación de prueba usando sus medidas características.

En un sentido, el hiperplano de margen máximo representa la línea media del bloque más ancho que podemos insertar entre las dos clases. Podemos calcular la distancia de cada observación de entrenamiento a un hiperplano de separación dado; la más pequeña de tales distancias es la distancia mínima de las observaciones al hiperplano y se conoce como el margen. El hiperplano de margen máximo es el hiperplano de separación para el cual el margen es el más grande-es decir, es el hiperplano que tiene la distancia mínima más lejana a las observaciones de entrenamiento-. En un espacio p-dimensional, un hiperplano es un subespacio plano de dimensión p-1 que no necesita pasar por el origen. En p dimensiones, un hiperplano se define por la ecuación

![Imagen8](C:/Users/Victor Miguel Terron/Documents/s11.png)


Podemos pensar al hiperplano como que divide el espacio p-dimensional en dos mitades. Por ejemplo, en dos dimensiones tenemos el hiperplano

![Imagen9](C:/Users/Victor Miguel Terron/Documents/s12.png)


![Imagen10](C:/Users/Victor Miguel Terron/Documents/s13.png)


![Imagen11](C:/Users/Victor Miguel Terron/Documents/s14.png)


![Imagen12](C:/Users/Victor Miguel Terron/Documents/s15.png)


![Imagen13](C:/Users/Victor Miguel Terron/Documents/s16.png)


![Imagen14](C:/Users/Victor Miguel Terron/Documents/s17.png)


![Imagen15](C:/Users/Victor Miguel Terron/Documents/s18.png)


El hiperplano de margen máximo es la solución al problema de optimización


![Imagen16](C:/Users/Victor Miguel Terron/Documents/s19.png)

sujeto a

![Imagen17](C:/Users/Victor Miguel Terron/Documents/s20.png)


![Imagen18](C:/Users/Victor Miguel Terron/Documents/s21.png)


## EL CASO NO SEPARABLE

Podemos extender el concepto de un hiperplano de separación para desarrollar un hiperplano que casi separa las clases usando lo que se conoce como un margen suave.


![Imagen19](C:/Users/Victor Miguel Terron/Documents/s22.png)

## CLASIFICADOR DE VECTORES DE SOPORTE

La distancia de una observación al hiperplano puede considerarse como una medida de nuestra confianza de que la observación se clasifica correctamente. Podemos estar dispuestos a considerar un clasificador basado en un hiperplano que no separe perfectamente las dos clases, con el interés de:
* Mayor robustez a observaciones individuales, y Mejor clasificación de la mayoría de las observaciones de prueba.

Es decir, podría valer la pena clasificar mal unas pocas observaciones de entrenamiento para hacer un mejor trabajo al clasificar las observaciones restantes. Un hiperplano que casi separa las clases es la solución al problema de optimización.

![Imagen20](C:/Users/Victor Miguel Terron/Documents/s23.png)


Sujeto a:

![Imagen21](C:/Users/Victor Miguel Terron/Documents/s24.png)


M es el ancho del margen; buscamos hacer esta cantidad tan grande como sea posible. Una vez que hemos resuelto el problema de optimización, clasificamos una observación de prueba x* como antes, al simplemente determinar de que lado del hiperplano se encuentra. Es decir, clasificamos la observación de prueba basados en el signo de

![Imagen22](C:/Users/Victor Miguel Terron/Documents/s25.png)


Conforme el presupuesto C se incrementa, nos volvemos más tolerantes con respecto a las violaciones al margen, y así el margen se hará ancho. Por otro lado, cuando C decrece, nos volvemos menos tolerantes a las violaciones al margen y así el margen se hace angosto. En la práctica, C es tratada como un parámetro que generalmente se elige por medio de validación-cruzada.
__Las observaciones que se encuentran directamente sobre los márgenes o del lado incorrecto del margen considerando su clase, se conocen como vectores de soporte. Clasificación con frontera de decisión no lineal.__

![Imagen23](C:/Users/Victor Miguel Terron/Documents/s26.png)

En el caso del clasificador de vectores de soporte, podemos tratar el problema de posibles fronteras no-lineales entre clases al ampliar el espacio de características usando funciones polinomiales cuadráticas, cúbicas, o incluso de orden superior de los predictores. Por ejemplo, en vez de ajustar un clasificador de vectores de soporte usando p características



![Imagen](C:/Users/Victor Miguel Terron/Documents/s27.png)

podríamos ajustar un clasificador de vectores de soporte usando 2p características


![Imagen](C:/Users/Victor Miguel Terron/Documents/s28.png)

Entonces el problema de optimización


![Imagen](C:/Users/Victor Miguel Terron/Documents/s29.png)



sujeto a 


![Imagen](C:/Users/Victor Miguel Terron/Documents/s30.png)


Se convertiría en:

![Imagen](C:/Users/Victor Miguel Terron/Documents/s31.png)



sujeto a



![Imagen](C:/Users/Victor Miguel Terron/Documents/s32.png)




No es difícil ver que hay muchas maneras de ampliar el espacio de características, y que a menos que seamos cuidadosos, podríamos terminar con un número enorme de características. Entonces los cálculos serían inmanejables.



## LA MAQUINA DE VECTORES DE SOPORTE

La máquina de vectores de soporte (SVM por sus siglas en inglés) es una extensión del clasificador de vectores de soporte que resulta de ampliar el espacio de características de una manera específica, usando kernels. Podemos querer ampliar nuestro espacio de características para acomodar una frontera no-lineal entre las clases. El enfoque del kernel que describimos aquí es simplemente un enfoque computacional eficiente para llevar a cabo esta idea.



![Imagen](C:/Users/Victor Miguel Terron/Documents/s33.png)

PUEDE DEMOSTRARSE QUE __1__. El clasificador de vectores de soporte lineal se puede representar como:

![Imagen](C:/Users/Victor Miguel Terron/Documents/s34.png)


donde hay $n$ parametros $i$,$i=1,...,n$, uno por observacion de entrenamiento.



![Imagen](C:/Users/Victor Miguel Terron/Documents/s35.png)


# KERNEL

Un kernel es la funcion que cuantifica la similaridad de dos observaciones.

## KERNEL LINEAL

![Imagen](C:/Users/Victor Miguel Terron/Documents/s36.png)


## KERNEL POLINOMIAL

![Imagen](C:/Users/Victor Miguel Terron/Documents/s37.png)


Cuando el clasificador de vectores de soporte se combina con un kernel no-lineal, el clasificador que resulta se conoce como una máquina de vectores de soporte. En este caso la función tiene la forma

![Imagen](C:/Users/Victor Miguel Terron/Documents/s38.png)


## KERNEL RADIAL

![Imagen](C:/Users/Victor Miguel Terron/Documents/s39.png)

Comportamiento local del kernel radial


![Imagen](C:/Users/Victor Miguel Terron/Documents/s40.png)


## CLASIFICACIÓN CON FRONTERA DE DECISION NO LINEAL

![Imagen](C:/Users/Victor Miguel Terron/Documents/s41.png)

¿Cuál es la ventaja de usar un kernel en lugar de simplemente ampliar el espacio de características usando funciones de las características originales?


![Imagen](C:/Users/Victor Miguel Terron/Documents/s42.png)


# EJEMPLO 1. REGRESION LINEAL SIMPLE

## OBJETIVO

Predecir una variable numérica a partir de otra variable predictora, cuando exista una relación aproximadamente lineal entre las variables y sea razonable asumir algunos supuestos.

## REQUISITOS

* Tener instalado R y RStudio
* Haber estudiado el Prework

```{r EJ5S5,comment=NA}
# Ejemplo 1. Regresión Lineal Simple

# Primero hay que establecer el directorio de trabajo y este deberá contener 
# el archivo de datos production.txt

# Leemos nuestros datos con la función read.table

production <- read.table("production.txt", header = TRUE)

# Los datos que importamos a R se encuentran como data frame con nombre 
# production. Aplicamos la función attach al data frame production para
# poder manipular las columnas mediante sus nombres

attach(production)

# Hacemos el gráfico de dispersión

plot(RunSize, RunTime, xlab = "Tamaño de ejecución", 
     ylab = "Tiempo de ejecución", pch = 16)

# Ajustamos un modelo de regresión lineal simple con la función lm, en donde
# la variable de respuesta es RunTime y la variable predictora es RunSize. 
# Guardamos nuestro modelo ajustado con el nombre de m1

m1 <- lm(RunTime~RunSize)

# Obtenemos un resumen de nuestro modelo ajustado mediante la función `summary`

summary(m1)

# Graficamos nuestros datos nuevamente, pero ahora con la recta de regresión
# ajustada

plot(RunSize, RunTime, xlab = "Tamaño de ejecución", 
     ylab = "Tiempo de ejecución", pch = 16)
abline(lsfit(RunSize, RunTime)) # Trazamos la recta de regresión estimada
mtext(expression(paste('Modelo de regresión lineal simple:',
                       ' ',
                       y[i] == beta[0] + beta[1]*x[i] + e[i])),
      side = 3, adj=1, font = 2)

# Recta de regresión poblacional

text(x = 200, y = 240, expression(paste('Recta de regresión:',
                                        ' ',
                                        y[i] == beta[0] + beta[1]*x[i])),
     adj = 1, font = 2)


# Recta de regresión estimada

text(x = 350, y = 180, expression(paste('Recta estimada:',
                                        ' ',
                                        hat(y)[i] == hat(beta)[0] + hat(beta)[1]*x[i])),
     adj = 1, font = 2)

# Recta de regresión estimada

text(x = 350, y = 160, expression(paste('Recta estimada:',
                                        ' ',
                                        hat(y)[i] == 149.74770 + 0.25924*x[i])),
     adj = 1, font = 2)

# Residuales

points(189, 215, pch=16, col = "red") # Punto muestral
149.74770 + 0.25924 * 189 # Valor y sobre la recta estimada
lines(c(189, 189), c(198.7441, 215), col = "red")

points(173, 166, pch=16, col = "red") # Punto muestral
149.74770 + 0.25924 * 173 # Valor y sobre la recta estimada
lines(c(173, 173), c(166, 194.5962), col = "red")

# Acontinuación encontramos el cuantil de orden 0.975 de la distribución
# t de Student con 18 (n - 2) grados de libertad. En total tenemos n = 20 
# observaciones en nuestro conjunto de datos. Estamos encontrando el valor 
# que satisface P(T > tval) = 0.025

tval <- qt(1-0.05/2, 18)
tval

# Comprobamos

pt(tval, df = 18)

# Encontramos intervalos de confianza del 95% para el intercepto y la pendiente
# del modelo de regresión lineal simple

round(confint(m1, level = 0.95), 3)

# Ahora encontramos intervalos de confianza del 95% para la recta de regresión
# poblacional en algunos valores de X (RunSize)

RunSize0 <- c(50,100,150,200,250,300,350) # Algunos posibles valores de RunSize

(conf <- predict(m1, newdata = 
                   data.frame(RunSize = RunSize0), 
                 interval = "confidence", level = 0.95))

# Podemos visualizar gráficamente estos intervalos de confianza

lines(RunSize0, conf[, 2], lty = 2, lwd = 2, col = "green") # límites inferiores
lines(RunSize0, conf[, 3], lty = 2, lwd = 2, col = "green") # límites superiores

# También podemos encontrar intervalos de predicción del 95% para el valor
# real de la variable de respuesta Y (RunTime) en algunos valores de X (RunSize)

(pred <- predict(m1, newdata = 
          data.frame(RunSize = RunSize0), 
        interval = "prediction", level = 0.95))

# Podemos visualizar gráficamente estos intervalos de predicción

lines(RunSize0, pred[, 2], lty = 2, lwd = 2, col = "blue") # límites inferiores
lines(RunSize0, pred[, 3], lty = 2, lwd = 2, col = "blue") # límites superiores


# Note como los intervalos de confianza están contenidos dentro de los
# intervalos de predicción correspondientes

# También es posible llevar a cabo un análisis de varianza para decidir si 
# existe asociación lineal entre RunSize y RunTime

anova(m1)

# Gráfico de diagnóstico de R

# Cuando usamos un modelo de regresión, hacemos una serie de suposiciones. 
# Entonces debemos hacer diagnósticos de regresión para verificar las
# supocisiones.

par(mfrow = c(2, 2))
plot(m1)
dev.off()

# Inspirado en:

# [S.J. Sheather, A Modern Approach to Regression with R, DOI: 10.1007/978-0-387-09608-7_2, © Springer Science + Business Media LLC 2009](https://gattonweb.uky.edu/sheather/book/index.php)

```

# RETO 1 REGRESION LINEAL SIMPLE

## OBJETIVO 

* Ajustar un modelo de regresión lineal simple a una muestra de datos, cuando parezca que existe una relación lineal entre las variables subyacentes
* Obtener gráficas de diagnóstico, para decidir si es razonable asumir algunos supuestos necesarios para el modelo de regresión lineal simple


## DESARROLLO

Se cree que entre las variables $x$ y $y$ del archivo csv adjunto, podría haber una relación más o menos lineal. Para tener más evidencia sobre esto lleve a cabo lo siguiente:

1. Realice el gráfico de dispersión de los datos
2. Ajuste un modelo de regresión lineal simple a los datos, muestre un resumen del modelo ajustado y trace la recta de regresión estimada junto con el gráfico de dispersión
3. Obtenga algunas gráficas de diagnóstico y diga si es razonable suponer para los errores aleatoriedad, normalidad y varianza constante.


```{r reto1session,comment=NA}
# Reto 1. Regresión lineal simple

# Se cree que entre las variables x y y del archivo csv adjunto, podría haber una relación más o menos lineal. Para tener más evidencia sobre esto lleve a cabo lo siguiente:
  
# 1. Realice el gráfico de dispersión de los datos
# 2. Ajuste un modelo de regresión lineal simple a los datos, muestre un resumen del modelo ajustado y trace la recta de regresión estimada junto con el gráfico de dispersión
# 3. Obtenga algunas gráficas de diagnóstico y diga si es razonable suponer para los errores aleatoriedad, normalidad y varianza constante.

# **Solución**

# Establezca primero un directorio de trabajo donde
# deberán estar los datos a importar
rm(list = ls()) # Para eliminar objetos creados previamente
datos <- read.csv("datos.csv")
attach(datos)
plot(x, y, main = "Gráfico de dispersión") # 1

modelo <- lm(y ~ x) # 2.
summary(modelo)
abline(lsfit(x, y))

par(mfrow = c(2, 2)) 
plot(modelo) # 3.

```

Primero hay que establecer el directorio de trabajo y este deberá contener el archivo de datos production.txt

Leemos nuestros datos con la función read.table

production <- read.table("production.txt", header = TRUE)
Los datos que importamos a R se encuentran como data frame con nombre production. Aplicamos la función attach al data frame production para poder manipular las columnas mediante sus nombres.

attach(production)
Hacemos el gráfico de dispersión

plot(RunSize, RunTime, xlab = "Tamaño de ejecución", 
     ylab = "Tiempo de ejecución", pch = 16)
Ajustamos un modelo de regresión lineal simple con la función lm, en donde la variable de respuesta es RunTime y la variable predictora es RunSize. Guardamos nuestro modelo ajustado con el nombre de m1.

m1 <- lm(RunTime~RunSize)
Obtenemos un resumen de nuestro modelo ajustado mediante la función summary

summary(m1)
Graficamos nuestros datos nuevamente, ahora con la recta de regresión estimada, mostrando algunas ecuaciones y algunos residuales gráficamente.

plot(RunSize, RunTime, xlab = "Tamaño de ejecución", 
     ylab = "Tiempo de ejecución", pch = 16)
abline(lsfit(RunSize, RunTime)) # Trazamos la recta de regresión estimada
mtext(expression(paste('Modelo de regresión lineal simple:',
                       ' ',
                       y[i] == beta[0] + beta[1]*x[i] + e[i])),
      side = 3, adj=1, font = 2)
      
# Recta de regresión poblacional

text(x = 200, y = 240, expression(paste('Recta de regresión:',
                                        ' ',
                                        y[i] == beta[0] + beta[1]*x[i])),
     adj = 1, font = 2)


# Recta de regresión estimada

text(x = 350, y = 180, expression(paste('Recta estimada:',
                                        ' ',
                                        hat(y)[i] == hat(beta)[0] + hat(beta)[1]*x[i])),
     adj = 1, font = 2)

# Recta de regresión estimada

text(x = 350, y = 160, expression(paste('Recta estimada:',
                                        ' ',
                                        hat(y)[i] == 149.74770 + 0.25924*x[i])),
     adj = 1, font = 2)

# Residuales

points(189, 215, pch=16, col = "red") # Punto muestral
149.74770 + 0.25924 * 189 # Valor y sobre la recta estimada
lines(c(189, 189), c(198.7441, 215), col = "red")

points(173, 166, pch=16, col = "red") # Punto muestral
149.74770 + 0.25924 * 173 # Valor y sobre la recta estimada
lines(c(173, 173), c(166, 194.5962), col = "red")
Acontinuación encontramos el cuantil de orden 0.975 de la distribución t de Student con 18 (n - 2) grados de libertad. En total tenemos n = 20 observaciones en nuestro conjunto de datos. Estamos encontrando el valor que satisface P(T > tval) = 0.025

tval <- qt(1-0.05/2, 18)
tval
Comprobamos

pt(tval, df = 18)
Encontramos intervalos de confianza del 95% para el intercepto y la pendiente del modelo de regresión lineal simple

round(confint(m1, level = 0.95), 3)
Ahora encontramos intervalos de confianza del 95% para la recta de regresión poblacional en algunos valores de X (RunSize)

RunSize0 <- c(50,100,150,200,250,300,350) # Algunos posibles valores de RunSize

(conf <- predict(m1, newdata = 
                   data.frame(RunSize = RunSize0), 
                 interval = "confidence", level = 0.95))

# Podemos visualizar gráficamente estos intervalos de confianza

lines(RunSize0, conf[, 2], lty = 2, lwd = 2, col = "green") # límites inferiores
lines(RunSize0, conf[, 3], lty = 2, lwd = 2, col = "green") # límites superiores
También podemos encontrar intervalos de predicción del 95% para el valor real de la variable de respuesta Y (RunTime) en algunos valores de X (RunSize)

(pred <- predict(m1, newdata = 
          data.frame(RunSize = RunSize0), 
        interval = "prediction", level = 0.95))

# Podemos visualizar gráficamente estos intervalos de predicción

lines(RunSize0, pred[, 2], lty = 2, lwd = 2, col = "blue") # límites inferiores
lines(RunSize0, pred[, 3], lty = 2, lwd = 2, col = "blue") # límites superiores
Note como los intervalos de confianza están contenidos dentro de los intervalos de predicción correspondientes.

También es posible llevar a cabo un análisis de varianza para decidir si existe asociación lineal entre RunSize y RunTime

anova(m1)
Gráficos de diagnóstico de R
Cuando usamos un modelo de regresión, hacemos una serie de suposiciones. Entonces debemos hacer diagnósticos de regresión para verificar las supocisiones.

par(mfrow = c(2, 2))
plot(m1)
dev.off()

# EJEMPLO 2. REGRESIÓN LINEAL MULTIPLE

## OBJETIVO

* Aprender como en ocasiones es posible predecir una variable numérica a partir de otras variables predictoras cuando exista una relación lineal entre las variables y sea razonable asumir algunos supuestos.

## DESARROLLO

Supongamos que queremos emprender un negocio o que se nos colicita un estudio en en cual se requiere predecir el precio de cena (platillo), para poder estar dentro de los rangos de precios del mercado y que el restaurante sea rentable.

Entonces primero vamos a analizar los datos de encuestas de clientes de 168 restaurantes Italianos en el área deseada que están disponibles, los cuales tienen las siguientes variables de estudio:
* Y: Price (Precio): el precio (en USD) de la cena
* X1: Food: Valuación del cliente de la comida (sacado de 30)
* X2: Décor: Valuación del cliente de la decoración (sacado de 30)
* X3: Service: Valuación del cliente del servicio (sacado de 30)
* X4: East: variable dummy: 1 (0) si el restaurante está al este (oeste) de la quinta avenida.


Primero debemos establecer nuestro directorio de trabajo y el archivo de datos (nyc.csv) que importaremos a R deberá de estar en este directorio.

nyc <- read.csv("nyc.csv", header = TRUE)
Observamos algunas filas y la dimensión del data frame

head(nyc, 2); tail(nyc, 2); dim(nyc)
attach(nyc)
Llevamos a cabo el ajuste de un modelo Y = beta0 + beta1Food + beta2Decor + beta3Service + beta4East + e

m1 <- lm(Price ~ Food + Decor + Service + East)
Obtenemos un resumen

summary(m1)
Ajustamos nuevamente un modelo pero ahora sin considerar la variable Service ya que en el resultado anterior se observó que su coeficiente de regresión no fue estadísticamente significativo Y = beta0 + beta1Food + beta2Decor + beta4*East + e (Reducido)

m2 <- lm(Price ~ Food + Decor + East)
Obtenemos un resumen del modelo ajustado

summary(m2)
Una forma alternativa de obtener m2 es usar el comando update

m2 <- update(m1, ~.-Service)
summary(m2)
Análisis de covarianza
Para investigar si el efecto de los predictores depende de la variable dummy East consideraremos el siguiente modelo el cual es una extensión a más de una variable predictora del modelo de rectas de regresión no relacionadas Y = beta0 + beta1Food + beta2Decor + beta3Service + beta4East + beta5FoodEast + beta6DecorEast + beta7ServiceEast + e (Completo)

mfull <- lm(Price ~ Food + Decor + Service + East + 
              Food:East + Decor:East + Service:East)
Note como ninguno de los coeficientes de regresión para los términos de interacción son estadísticamente significativos

summary(mfull)
Ahora compararemos el modelo completo guardado en mfull contra el modelo reducido guardado en m2. Es decir, llevaremos a cabo una prueba de hipótesis general de

H0: beta3 = beta5 = beta6 = beta7 = 0

es decir Y = beta0 + beta1Food + beta2Decor + beta4*East + e (Reducido)

contra

H1: H0 no es verdad

es decir, Y = beta0 + beta1Food + beta2Decor + beta3Service + beta4East + beta5FoodEast + beta6DecorEast + beta7ServiceEast + e (Completo)

La prueba de si el efecto de los predictores depende de la variable dummy East puede lograrse usando la siguiente prueba-F parcial.

anova(m2,mfull)
Dado que el p-value es aproximadamente 0.36, fallamos en rechazar la hipótesis nula y adopatamos el modelo reducido Y = beta0 + beta1Food + beta2Decor + beta4*East + e (Reducido)

Diagnósticos
En regresión múltiple, las gráficas de residuales o de residuales estandarizados proporcionan información directa sobre la forma en la cual el modelo está mal especificado cuando se cumplen las siguientes dos condiciones:

E(Y | X = x) = g(beta0 + beta1x1 + ... + betapxp)

y

E(Xi | Xj) aprox alpha0 + alpha1*Xj

Cuando estas condiciones se cumplen, la gráfica de Y contra los valores ajustados, proporciona información directa acerca de g. En regresión lineal múltiple g es la función identidad. En este caso la gráfica de Y contra los valores ajustados debe producir puntos dispersos alrededor de una recta. Si las condiciones no se cumplen, entonces un patrón en la gráfica de los residuales indica que un modelo incorrecto ha sido ajustado, pero el patrón mismo no proporciona información directa sobre como el modelo está mal específicado.

Ahora tratemos de verificar si el modelo ajustado es un modelo válido.

Acontinuación mostramos una matriz de gráficos de dispersión de los tres predictores continuos. Los predictores parecen estar linealmente relacionados al menos aproximadamente

pairs(~ Food + Decor + Service, data = nyc, gap = 0.4, cex.labels = 1.5)
Acontinuación veremos gráficas de residuales estandarizados contra cada predictor. La naturaleza aleatoria de estas gráficas es un indicativo de que el modelo ajustado es un modelo válido para los datos.

m1 <- lm(Price ~ Food + Decor + Service + East)
summary(m1)
StanRes1 <- rstandard(m1)
par(mfrow = c(2, 2))
plot(Food, StanRes1, ylab = "Residuales Estandarizados")
plot(Decor, StanRes1, ylab = "Residuales Estandarizados")
plot(Service, StanRes1, ylab = "Residuales Estandarizados")
plot(East, StanRes1, ylab = "Residuales Estandarizados")
dev.off()
Finalmente mostramos una gráfica de Y, el precio contra los valores ajustados

plot(m1$fitted.values, Price, xlab = "Valores ajustados", ylab = "Price")
abline(lsfit(m1$fitted.values, Price))


```{r EJ2S5,comment=NA}
# Ejemplo 2. Regresión Lineal Múltiple

# Predecir el precio de cena (platillo). 
# Datos de encuestas de clientes de 168 restaurantes Italianos
# en el área deseada están disponibles.

# Y: Price (Precio): el precio (en USD) de la cena
# X1: Food: Valuación del cliente de la comida (sacado de 30)
# X2: Décor: Valuación del cliente de la decoración (sacado de 30)
# X3: Service: Valuación del cliente del servicio (sacado de 30)
# X4: East: variable dummy: 1 (0) si el restaurante está al este (oeste) de la quinta avenida

# Primero debemos establecer nuestro directorio de trabajo y el archivo
# de datos (nyc.csv) que importaremos a R deberá de estar en este directorio

nyc <- read.csv("nyc.csv", header = TRUE)

# Observamos algunas filas y la dimensión del data frame

head(nyc, 2); tail(nyc, 2); dim(nyc)
attach(nyc)

# Llevamos a cabo el ajuste de un modelo
# Y = beta0 + beta1*Food + beta2*Decor + beta3*Service + beta4*East + e

m1 <- lm(Price ~ Food + Decor + Service + East)

# Obtenemos un resumen

summary(m1)

# Ajustamos nuevamente un modelo pero ahora sin considerar la variable Service
# ya que en el resultado anterior se observó que su coeficiente de regresión
# no fue estadísticamente significativo

# Y = beta0 + beta1*Food + beta2*Decor + beta4*East + e (Reducido)

m2 <- lm(Price ~ Food + Decor + East)

# Obtenemos un resumen del modelo ajustado

summary(m2)

# Una forma alternativa de obtener m2 es usar el comando update

m2 <- update(m1, ~.-Service)
summary(m2)

######

# Análisis de covarianza

# Para investigar si el efecto de los predictores depende de la variable dummy 
# East consideraremos el siguiente modelo el cual es una extensión a más de una 
# variable predictora del modelo de rectas de regresión no relacionadas 
# Y = beta0 + beta1*Food + beta2*Decor +  beta3*Service + beta4*East 
#           + beta5*Food*East + beta6*Decor*East + beta7*Service*East + e (Completo)

mfull <- lm(Price ~ Food + Decor + Service + East + 
              Food:East + Decor:East + Service:East)

# Note como ninguno de los coeficientes de regresión para los
# términos de interacción son estadísticamente significativos

summary(mfull)

# Ahora compararemos el modelo completo guardado en mfull contra el modelo
# reducido guardado en m2. Es decir, llevaremos a cabo una prueba de hipótesis
# general de

# H0: beta3 = beta5 = beta6 = beta7 = 0
# es decir Y = beta0 + beta1*Food + beta2*Decor + beta4*East + e (Reducido)
# contra
# H1: H0 no es verdad
# es decir, 
# Y = beta0 + beta1*Food + beta2*Decor +  beta3*Service + beta4*East 
#           + beta5*Food*East + beta6*Decor*East + beta7*Service*East + e (Completo)

# La prueba de si el efecto de los predictores depende de la variable dummy
# East puede lograrse usando la siguiente prueba-F parcial.

anova(m2,mfull)

# Dado que el p-value es aproximadamente 0.36, fallamos en rechazar la hipótesis
# nula y adopatamos el modelo reducido
# Y = beta0 + beta1*Food + beta2*Decor + beta4*East + e (Reducido)

######

# Diagnósticos

# En regresión múltiple, las gráficas de residuales o de residuales
# estandarizados proporcionan información directa sobre la forma
# en la cual el modelo está mal especificado cuando se cumplen
# las siguientes dos condiciones:

# E(Y | X = x) = g(beta0 + beta1*x1 + ... + betap*xp) y
# E(Xi | Xj) aprox alpha0 + alpha1*Xj

# Cuando estas condiciones se cumplen, la gráfica de Y contra
# los valores ajustados, proporciona información directa acerca de g.
# En regresión lineal múltiple g es la función identidad. En
# este caso la gráfica de Y contra los valores ajustados
# debe producir puntos dispersos alrededor de una recta.
# Si las condiciones no se cumplen, entonces un patrón en la
# gráfica de los residuales indica que un modelo incorrecto
# ha sido ajustado, pero el patrón mismo no proporciona 
# información directa sobre como el modelo está mal específicado.

# Ahora tratemos de verificar si el modelo ajustado es un modelo válido.

# Acontinuación mostramos una matriz de gráficos de dispersión de los
# tres predictores continuos. Los predictores parecen estar linealmente
# relacionados al menos aproximadamente

pairs(~ Food + Decor + Service, data = nyc, gap = 0.4, cex.labels = 1.5)

# Acontinuación veremos gráficas de residuales estandarizados contra cada
# predictor. La naturaleza aleatoria de estas gráficas es un indicativo de
# que el modelo ajustado es un modelo válido para los datos.

m1 <- lm(Price ~ Food + Decor + Service + East)
summary(m1)
StanRes1 <- rstandard(m1)
par(mfrow = c(2, 2))
plot(Food, StanRes1, ylab = "Residuales Estandarizados")
plot(Decor, StanRes1, ylab = "Residuales Estandarizados")
plot(Service, StanRes1, ylab = "Residuales Estandarizados")
plot(East, StanRes1, ylab = "Residuales Estandarizados")
dev.off()

# Finalmente mostramos una gráfica de Y, el precio contra los valores
# ajustados 

plot(m1$fitted.values, Price, xlab = "Valores ajustados", ylab = "Price")
abline(lsfit(m1$fitted.values, Price))

# Inspirado en:

# [S.J. Sheather, A Modern Approach to Regression with R, DOI: 10.1007/978-0-387-09608-7_2, © Springer Science + Business Media LLC 2009](https://gattonweb.uky.edu/sheather/book/index.php)

```

# EJEMPLO 3 MAQUINAS DE VECTORES DE SOPORTE COMPAÑÍA DE TARJETAS DE CREDITO


## OBJETIVO

* Clasificar clientes potenciales de una compañía de tarjetas de crédito usando máquinas de vectores de soporte


## DESARROLLO

Paquetes de R utilizados

suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(e1071)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(ISLR)))
Observemos algunas características del data frame Default del paquete ISLR, con funciones tales como head, tail, dim y str.
?Default
head(Default)
tail(Default)
dim(Default)
str(Default)
Usando ggplot del paquete ggplot2, realicemos un gráfico de dispersión con la variable balance en el eje x, la variable income en el eje y, diferenciando las distintas categorías en la variable default usando el argumento colour. Lo anterior para estudiantes y no estudiantes usando facet_wrap.
ggplot(Default, aes(x = balance, y = income, colour = default)) + 
  geom_point() + facet_wrap('student') + 
  theme_grey() + ggtitle("Datos Default")
Generemos un vector de índices llamado train, tomando de manera aleatoria 5000 números de los primeros 10,000 números naturales, esto servirá para filtrar el conjunto de entrenamiento y el conjunto de prueba del data frame Default. Realicemos el gráfico de dispersión análogo al punto 2, pero para los conjuntos de entrenamiento y de prueba.
set.seed(2020)
train = sample(nrow(Default), 
               round(nrow(Default)/2))
tail(Default[train, ])

ggplot(Default[train, ], 
       aes(x = balance, y = income, colour = default)) + 
  geom_point() + facet_wrap('student') + 
  theme_dark() + ggtitle("Conjunto de entrenamiento")

ggplot(Default[-train, ], 
       aes(x = balance, y = income, colour = default)) + 
  geom_point() + facet_wrap('student') + 
  theme_light() + ggtitle("Conjunto de prueba")
Ahora utilicemos la función tune junto con la función svm para seleccionar el mejor modelo de un conjunto de modelos, los modelos considerados serán aquellos obtenidos al variar los valores de los parámetros cost y gamma (usaremos un kernel radial).
# Ahora utilizamos la función `tune` junto con la función `svm` para 
# seleccionar el mejor modelo de un conjunto de modelos, los modelos 
# considerados son aquellos obtenidos al variar los valores de los 
# parámetros `cost` y `gamma`. Kernel Radial

#tune.rad = tune(svm, default~., data = Default[train,], 
#                kernel = "radial", 
#                ranges = list(
#                  cost = c(0.1, 1, 10, 100, 1000), 
#                  gamma = seq(0.01, 10, 0.5)
#                ) 
#)

# Se ha elegido el mejor modelo utilizando *validación cruzada de 10 
# iteraciones*

# summary(tune.rad)

# Aquí un resumen del modelo seleccionado

# summary(tune.rad$best.model)

best <- svm(default~.,  data = Default[train,],
            kernel = "radial",
            cost = 100,
            gamma = 1.51
            )
Con el mejor modelo seleccionado y utilizando el conjunto de prueba, obtengamos una matriz de confusión, para observar el número de aciertos y errores cometidos por el modelo. También obtengamos la proporción total de aciertos y la matriz que muestre las proporciones de aciertos y errores cometidos pero por categorías.
mc <- table(true = Default[-train, "default"], 
            pred = predict(best, 
                           newdata = Default[-train,]))
mc

# El porcentaje total de aciertos obtenido por el modelo usando el 
# conjunto de prueba es el siguiente

round(sum(diag(mc))/sum(colSums(mc)), 5)

# Ahora observemos las siguientes proporciones

rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
Ajustemos nuevamente el mejor modelo, pero ahora con el argumento decision.values = TRUE. Obtengamos los valores predichos para el conjunto de prueba utilizando el mejor modelo, las funciones predict, attributes y el argumento decision.values = TRUE dentro de predict.
fit <- svm(default ~ ., data = Default[train,], 
           kernel = "radial", cost = 100, gamma = 1.51,
           decision.values = TRUE)

fitted <- attributes(predict(fit, Default[-train,], 
                             decision.values = TRUE))$decision.values
Realicemos clasificación de las observaciones del conjunto de prueba utilizando los valores predichos por el modelo y un umbral de decisión igual a cero. También obtengamos la matriz de confusión y proporciones como anteriormente hicimos.
eti <- ifelse(fitted < 0, "Yes", "No")

mc <- table(true = Default[-train, "default"], 
            pred = eti)
mc

round(sum(diag(mc))/sum(colSums(mc)), 5)

rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)
Repitamos el paso 7 pero con un umbral de decisión diferente, de tal manera que se reduzca la proporción del error más grave para la compañía de tarjetas de crédito.
eti <- ifelse(fitted < 1.002, "Yes", "No")

mc <- table(true = Default[-train, "default"], 
            pred = eti)
mc

round(sum(diag(mc))/sum(colSums(mc)), 5)

rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)


```{r DS5EX,comment=NA}
# Ejemplo 3. Máquinas de vectores de soporte (Compañía de tarjetas de crédito)

# Paquetes de R utilizados

suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(e1071)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(ISLR)))

# 1. Observemos algunas características del data frame Default del paquete ISLR, con funciones tales como head, tail, dim y str.

?Default
head(Default)
tail(Default)
dim(Default)
str(Default)

# 2. Usando ggplot del paquete ggplot2, realicemos un gráfico de dispersión con la variable balance en el eje x, la variable income en el eje y, diferenciando las distintas categorías en la variable default usando el argumento colour. Lo anterior para estudiantes y no estudiantes usando facet_wrap.

ggplot(Default, aes(x = balance, y = income, colour = default)) + 
  geom_point() + facet_wrap('student') + 
  theme_grey() + ggtitle("Datos Default")

# 3. Generemos un vector de índices llamado train, tomando de manera aleatoria 5000 números de los primeros 10,000 números naturales, esto servirá para filtrar el conjunto de entrenamiento y el conjunto de prueba del data frame Default. Realicemos el gráfico de dispersión análogo al punto 2, pero para los conjuntos de entrenamiento y de prueba.

set.seed(2020)
train = sample(nrow(Default), 
               round(nrow(Default)/2))
tail(Default[train, ])

ggplot(Default[train, ], 
       aes(x = balance, y = income, colour = default)) + 
  geom_point() + facet_wrap('student') + 
  theme_dark() + ggtitle("Conjunto de entrenamiento")

ggplot(Default[-train, ], 
       aes(x = balance, y = income, colour = default)) + 
  geom_point() + facet_wrap('student') + 
  theme_light() + ggtitle("Conjunto de prueba")

# 4. Ahora utilicemos la función tune junto con la función svm para seleccionar el mejor modelo de un conjunto de modelos, los modelos considerados serán aquellos obtenidos al variar los valores de los parámetros cost y gamma (usaremos un kernel radial).

# Ahora utilizamos la función `tune` junto con la función `svm` para 
# seleccionar el mejor modelo de un conjunto de modelos, los modelos 
# considerados son aquellos obtenidos al variar los valores de los 
# parámetros `cost` y `gamma`. Kernel Radial

#tune.rad = tune(svm, default~., data = Default[train,], 
#                kernel = "radial", 
#                ranges = list(
#                  cost = c(0.1, 1, 10, 100, 1000), 
#                  gamma = seq(0.01, 10, 0.5)
#                ) 
#)

# Se ha elegido el mejor modelo utilizando *validación cruzada de 10 
# iteraciones*

# summary(tune.rad)

# Aquí un resumen del modelo seleccionado

# summary(tune.rad$best.model)

best <- svm(default~.,  data = Default[train,],
            kernel = "radial",
            cost = 100,
            gamma = 1.51
            )

# 5. Con el mejor modelo seleccionado y utilizando el conjunto de prueba, obtengamos una matriz de confusión, para observar el número de aciertos y errores cometidos por el modelo. También obtengamos la proporción total de aciertos y la matriz que muestre las proporciones de aciertos y errores cometidos pero por categorías.

mc <- table(true = Default[-train, "default"], 
            pred = predict(best, 
                           newdata = Default[-train,]))
mc

# El porcentaje total de aciertos obtenido por el modelo usando el 
# conjunto de prueba es el siguiente

round(sum(diag(mc))/sum(colSums(mc)), 5)

# Ahora observemos las siguientes proporciones

rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)

# 6. Ajustemos nuevamente el mejor modelo, pero ahora con el argumento decision.values = TRUE. Obtengamos los valores predichos para el conjunto de prueba utilizando el mejor modelo, las funciones predict, attributes y el argumento decision.values = TRUE dentro de predict.

fit <- svm(default ~ ., data = Default[train,], 
           kernel = "radial", cost = 100, gamma = 1.51,
           decision.values = TRUE)

fitted <- attributes(predict(fit, Default[-train,], 
                             decision.values = TRUE))$decision.values

# 7. Realicemos clasificación de las observaciones del conjunto de prueba utilizando los valores predichos por el modelo y un umbral de decisión igual a cero. También obtengamos la matriz de confusión y proporciones como anteriormente hicimos.

eti <- ifelse(fitted < 0, "Yes", "No")

mc <- table(true = Default[-train, "default"], 
            pred = eti)
mc

round(sum(diag(mc))/sum(colSums(mc)), 5)

rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)

# 8. Repitamos el paso 7 pero con un umbral de decisión diferente, de tal manera que se reduzca la proporción del error más grave para la compañía de tarjetas de crédito.

eti <- ifelse(fitted < 1.002, "Yes", "No")

mc <- table(true = Default[-train, "default"], 
            pred = eti)
mc

round(sum(diag(mc))/sum(colSums(mc)), 5)

rs <- apply(mc, 1, sum)
r1 <- round(mc[1,]/rs[1], 5)
r2 <- round(mc[2,]/rs[2], 5)
rbind(No=r1, Yes=r2)

```

# RETO 2 MAQUINAS DE VECTORES DE SOPORTE

## OBJETIVO

* Crear un conjunto de entrenamiento y uno de prueba a partir de un conjunto de datos dado
* Ajustar máquinas de vectores de soporte a un conjunto de entrenamiento
* Llevar a cabo clasificación con un conjunto de prueba y crear la matriz de confusión

## DESARROLLO


En el archivo de datos csv adjunto se encuentran observaciones correspondientes a dos clases diferentes indicadas por la variable y. Únicamente hay dos variables predictoras o características. A continuación realice los siguientes requerimientos (Hint: transforme primero la variable de respuesta y a variable categórica con las funciones mutate y factor):

1. Carga los paquetes ggplot2 y e1071; observe algunas características del data frame con las funciones tail y dim. Obtenga el gráfico de dispersión de los datos diferenciando las dos clases.

2. Genera de manera aleatoria un vector de índices para filtrar un conjunto de entrenamiento a partir del conjunto de datos dado. Con ayuda de las funciones tune y svm ajuste máquinas de vectores de soporte con un kernel radial a los datos de entrenamiento, para valores del parámetro cost igual a 0.1, 1, 10, 100, 1000 y valores del parámetro gamma igual a 0.5, 1, 2, 3, 4. Obtenga un resumen de los resultados.

3. Con el modelo que tuvo el mejor desempeño en el paso anterior realiza clasificación con la función predict y el conjunto de datos de prueba. Muestre la matriz de confusión.

```{r R2SS5,comment=NA}
# Reto 2. Máquinas de vectores de soporte

# En el archivo de datos csv adjunto se encuentran observaciones correspondientes a dos clases diferentes indicadas por la variable y. Únicamente hay dos variables predictoras o características. Realice lo siguiente:

# 1. Cargue los paquetes ggplot2 y e1071; observe algunas características
# del data frame con las funciones tail y dim. Obtenga el gráfico de 
# dispersión de los datos diferenciando las dos clases.
# 2. Genere de manera aleatoria un vector de índices para filtrar un 
# conjunto de entrenamiento a partir del conjunto de datos dado.
# Con ayuda de las funciones tune y svm ajuste máquinas de vectores 
# de soporte con un kernel radial a los datos de entrenamiento, 
# para valores del parámetro cost igual a 0.1, 1, 10, 100, 1000 
# y valores del parámetro gamma igual a 0.5, 1, 2, 3, 4. 
# Obtenga un resumen de los resultados.
# 3. Con el modelo que tuvo el mejor desempeño en el
# paso anterior realice clasificación con la función 
# predict y el conjunto de datos de prueba. Muestre la matriz de confusión.

# **Solución**

# Primero establecemos nuestro directorio de trabajo en donde
# deberán estar nuestros datos.

datos <- read.csv("datosclases.csv")

# 1. 

# Cargamos los paquetes `ggplot2` y `e1071`,
# observamos algunas características del data frame
# con las funciones `tail` y `dim`.

library(dplyr)
library(ggplot2)
library(e1071)

###

tail(datos); dim(datos); str(datos)
datos <- mutate(datos, y = factor(y))
# Obtenemos el gráfico de dispersión de los datos
# diferenciando las dos clases

ggplot(datos, aes(x = x.1, y = x.2, colour = y)) + 
  geom_point() + 
  theme_dark() + ggtitle("Datos")

###

# 2.

# Generamos índices para el conjunto de entrenamiento

train <- sample(300, 150)
tail(as.data.frame(train))

###

# Ajustamos máquinas de vectores de soporte con un kernel radial 
# para diferentes valores de los parámetros `cost` y `gamma`

set.seed(67)
tune.out <- tune(svm, y~., data = datos[train, ], 
                 kernel = "radial", 
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000), 
                               gamma = c(0.5, 1, 2, 3, 4)))


### Obtenemos un resumen de los modelos ajustados y su desempeño

summary(tune.out)


###

# Realizamos clasificación con el mejor modelo ajustado y obtenemos
# la matriz de confusión.

table(true = datos[-train, "y"], 
      pred = predict(tune.out$best.model, newdata = datos[-train,]))

```

# EJEMPLO 4. MAQUINAS DE VECTORES DE SOPORTE

## OBJETIVO

* Conocer algunas funciones de R que nos ayudarán a llevar a cabo clasificaciones. Aprenderemos a dividir un conjunto de datos dado, en dos conjuntos, uno llamado el conjunto de entrenamiento y el otro llamado el conjunto de prueba; desarrollaremos un clasificador con ayuda de R y del conjunto de entrenamiento y evaluaremos su desempeño con el conjunto de prueba. En la práctica, un clasificador de esta naturaleza podría ser usado para ayudar a hacer diagnósticos de enfermedades, para decidir a quien otorgarle un crédito o a quien no y en general para clasificar personas en una de dos o más categorías.


## DESARROLLO

Clasificador de vectores de soporte
Vamos a comenzar cargando el paquete e1071 para ajustar máquinas de vectores de soporte

# install.packages("e1071") para instalarlo
library(e1071) 
Generamos observaciones correspondientes a dos clases

set.seed(754)
x <- matrix(rnorm(30*2), ncol = 2)
y <- c(rep(-1, 15), rep(1, 15))
x[y == 1, ] <- x[y == 1, ] + 1
plot(x, col = (3-y), pch = 16)
Creamos un data frame con la respuesta como factor, está nos ayudará a realizar la clasificación

dat <- data.frame(x = x, y = as.factor(y))
tail(dat)
Ajustamos el clasificador de vectores de soporte con la función svm

svmfit <- svm(y~., data = dat, kernel = "linear", 
              cost = 10, scale = FALSE)
Acontinuación, mostramos el clasificador de vectores de soporte junto con las observaciones. Los vectores de soporte se muestran como x's

plot(svmfit, dat)
También podemos observar los índices (números de filas en el data frame) que corresponden a vectores de soporte

svmfit$index
length(svmfit$index)
Mostramos un breve resumen del ajuste

summary(svmfit)
Volvemos a realizar el ajuste pero ahora con el valor del parámetro cost = 0.1

svmfit <- svm(y~., data = dat, kernel = "linear", 
              cost = 0.1, scale = FALSE)
Se grafica el clasificador

plot(svmfit, dat)
Tenemos más vectores de soporte

length(svmfit$index)
svmfit$index
El siguiente comando indica que queremos comparar MVS con un kernel lineal, usando un rango de valores del parámetro cost

set.seed(524)
tune.out <- tune(svm, y~., data = dat, kernel = "linear", 
                 ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
Elegimos el mejor modelo ajustado

bestmod <- tune.out$best.model
summary(bestmod)
Ahora consideramos un conjunto de datos de prueba para poder evaluar nuestro clasificador

xtest <- matrix(rnorm(45*2), ncol = 2)
ytest <- sample(c(-1, 1), 45, rep = TRUE)
xtest[ytest == 1, ] <- xtest[ytest == 1, ] + 1
testdat <- data.frame(x = xtest, y = as.factor(ytest))
tail(testdat)
Realizamos una clasificación usando el mejor modelo ajustado y el conjunto de datos de prueba. Luego, mostramos la matriz de confusión

ypred <- predict(bestmod, testdat)
table(predict = ypred, truth = testdat$y)
Máquinas de vectores de soporte
Generamos datos con una frontera de clase no lineal

set.seed(6891)
x <- matrix(rnorm(200*2), ncol = 2)
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] - 2
y <- c(rep(1, 150), rep(2, 50))
dat <- data.frame(x = x, y = as.factor(y))
head(dat)
plot(x, col = y, pch = 16)
Generamos índices para el conjunto de entrenamiento

train <- sample(200, 100)
tail(as.data.frame(train))
Ajustamos una máquina de vectores de soporte con un kernel radial y valores de los parámetros gamma = 1 y cost = 1

svmfit <- svm(y~., data = dat[train, ], 
              kernel = "radial", gamma = 1, cost = 1)
	      
plot(svmfit, dat[train, ])
summary(svmfit)
Ajustamos una máquina de vectores de soporte con un kernel radial y valores de los parámetros gamma = 1 y cost = 1e5

svmfit <- svm(y~., data = dat[train, ], 
              kernel = "radial", gamma = 1, cost = 1e5)
plot(svmfit, dat[train, ])
Ajustamos máquinas de vectores de soporte con un kernel radial para diferentes valores de los parámetros cost y gamma

set.seed(1980)
tune.out <- tune(svm, y~., data = dat[train, ], kernel = "radial", 
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000), 
                               gamma = c(0.5, 1, 2, 3, 4)))
summary(tune.out)
Realizamos clasificación con el mejor modelo ajustado y obtenemos la matriz de confusión, esta matriz servirá para conocer los valores ajustados correctamente

table(true = dat[-train, "y"], 
      pred = predict(tune.out$best.model, newdata = dat[-train,]))
      
      
```{r ej4sess5,comment=NA}
# Ejemplo 4. Máquinas de Vectores de Soporte

#### Clasificador de vectores de soporte

# Cargamos el paquete `e1071` para ajustar máquinas de vectores de soporte


# install.packages("e1071") para instalarlo
library(e1071) 


###
  
# Generamos observaciones correspondientes a dos clases


set.seed(754)
x <- matrix(rnorm(30*2), ncol = 2)
y <- c(rep(-1, 15), rep(1, 15))
x[y == 1, ] <- x[y == 1, ] + 1


###
  
  
plot(x, col = (3-y), pch = 16)


###
  
# Creamos un data frame con la respuesta como factor


dat <- data.frame(x = x, y = as.factor(y))
tail(dat)


###
  
# Ajustamos el clasificador de vectores de soporte con la función `svm`


svmfit <- svm(y~., data = dat, kernel = "linear", 
              cost = 10, scale = FALSE)


# Acontinuación, mostramos el clasificador de vectores de soporte junto con las observaciones. Los vectores de soporte se muestran como $x's$

###


plot(svmfit, dat)


###

# También podemos observar los índices (números de filas en el data frame) que corresponden a vectores de soporte


svmfit$index



length(svmfit$index)


###

# Mostramos un breve resumen del ajuste

summary(svmfit)


###

# Volvemos a realizar el ajuste pero ahora con el valor del parámetro `cost = 0.1`


svmfit <- svm(y~., data = dat, kernel = "linear", 
cost = 0.1, scale = FALSE)


###


plot(svmfit, dat)


###

# Tenemos más vectores de soporte


length(svmfit$index)

svmfit$index

###

# El siguiente comando indica que queremos comparar MVS con un kernel lineal, usando un rago de valores del parámetro `cost`

set.seed(524)
tune.out <- tune(svm, y~., data = dat, kernel = "linear", 
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))


###

summary(tune.out)


###

# Elegimos el mejor modelo ajustado


bestmod <- tune.out$best.model


###


summary(bestmod)


###

# Ahora consideramos un conjunto de datos de prueba


xtest <- matrix(rnorm(45*2), ncol = 2)
ytest <- sample(c(-1, 1), 45, rep = TRUE)
xtest[ytest == 1, ] <- xtest[ytest == 1, ] + 1
testdat <- data.frame(x = xtest, y = as.factor(ytest))
tail(testdat)


###

# Realizamos una clasificación usando el mejor modelo ajustado y el conjunto de datos de prueba. Luego, mostramos la matriz de confusión


ypred <- predict(bestmod, testdat)
table(predict = ypred, truth = testdat$y)


###

#### Máquinas de vectores de soporte

# Generamos datos con una frontera de clase no lineal


set.seed(6891)
x <- matrix(rnorm(200*2), ncol = 2)
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] - 2
y <- c(rep(1, 150), rep(2, 50))
dat <- data.frame(x = x, y = as.factor(y))
head(dat)


###


plot(x, col = y, pch = 16)


###

# Generamos índices para el conjunto de entrenamiento

train <- sample(200, 100)
tail(as.data.frame(train))


###

# Ajustamos una máquina de vectores de soporte con un kernel radial y valores de los parámetros `gamma = 1` y `cost = 1`

svmfit <- svm(y~., data = dat[train, ], 
kernel = "radial", gamma = 1, cost = 1)


###


plot(svmfit, dat[train, ])


###

summary(svmfit)

###

# Ajustamos una máquina de vectores de soporte con un kernel radial y valores de los parámetros `gamma = 1` y `cost = 1e5`

svmfit <- svm(y~., data = dat[train, ], 
kernel = "radial", gamma = 1, cost = 1e5)


###


plot(svmfit, dat[train, ])


###

# Ajustamos máquinas de vectores de soporte con un kernel radial para diferentes valores de los parámetros `cost` y `gamma`

set.seed(1980)
tune.out <- tune(svm, y~., data = dat[train, ], kernel = "radial", 
ranges = list(cost = c(0.1, 1, 10, 100, 1000), 
gamma = c(0.5, 1, 2, 3, 4)))


###

summary(tune.out)


###

# Realizamos clasificación con el mejor modelo ajustado y obtenemos la matriz de confusión.

table(true = dat[-train, "y"], 
pred = predict(tune.out$best.model, newdata = dat[-train,]))

```
      
