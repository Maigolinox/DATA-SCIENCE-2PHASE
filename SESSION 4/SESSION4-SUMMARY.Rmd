---
title: "SESSION 4 SUMMARY"
author: "Victor Miguel Terrón Macias"
date: "21/1/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# SESSION 4. ALGUNAS DISTRIBUCIONES, TEOREMA CENTRAL DEL LÍMITE Y CONTRASTE DE HIPOTESIS

# CONCEPTOS DE ESTADÍSTICA INFERENCIAL BÁSICOS

## DISTRIBUCIÓN BINOMIAL

Se define como un experimento con las siguientes características:
* Consiste en un número fijo, $n$, de pruebas idénticas.
* Cada prueba resulta en uno de dos resultados: éxito $S$ o fracaso $F$
* La probabilidad de éxito en una sola prueba es igual a algún valor p y es la misma de una prueba a otra. La probabilidad de fracaso es igual a $q=1-p$
* Las pruebas son independientes
* La variable aleatoria (v.a.discreta) de interés es Y, el número de éxitos observado durante las $n$ pruebas. 

Se dice que una variable aleatoria Y tiene una distribución binomial basada en $n$ pruebas con probabilidad $p$ de éxito, si y solo si. $$P_x= \left( \begin{matrix} n\\ x  \end{matrix}\right)p^x q^{m-x}$$

De donde $P$ es probabilidad binomial, de donde $x$ es el numero de veces para obtener un resultado específico en $n$ ensayos, de donde $\left( \begin{matrix} n\\ x  \end{matrix}\right)$, de donde $p$ es la probabilidad de exito en un solo ensayo,$q$ es probabilidad de fallo en un solo ensayo y $n$ es el numero de ensayos. Y donde $P$ que es la posibilidad tiene que cumplir con $0\leq P\leq 1$

### EJEMPLO DE APLICACION DE DISTRIBUCION BINOMIAL

La última novela de un autor ha tenido un gran éxito, hasta el punto de que el 80% de los lectores ya la han leído. Hallar la probabilidad de que en un grupo de 4 amigos que son aficionados a la lectura, 2 hayan leído la novela.

1. Hallar la probabilidad de que una persona haya leído el libro es de 0.8, por lo que la probabilidad de que no lo haya leído es de 0.2. De donde tenemos los siguientes datos:
$n=4,k=2,p=0.8,q=0.2$

2. Hallar la probabilidad de que máximo 2 personas del grupo de 4 amigos hayan leído la novela: tenemos los siguientes datos:

$$P(x\leq2)=P(x=0)+P(x=1)+P(x=2)$$ 

Sustituyendo los datos en la fomrula de distribución binomial tenemos lo siguiente:

$$P_{x\leq2} = \left( \begin{matrix} 4\\ 0  \end{matrix}\right)(0.8)^0 (0.2)^{4-0} +\left( \begin{matrix} 4\\ 1  \end{matrix}\right)(0.8)^1(0.2)^{4-1} +\left( \begin{matrix} 4\\ 2  \end{matrix}\right)(0.8)^2(0.2)^{4-2}=0.1808 $$


## DISTRIBUCIÓN NORMAL

A una distribución normal se le conoce como distribución Gaussiana o distribucion de Laplace Gauss. Se utiliza csolamente con variables continuas (variables que pueden tomar un numero infinito de valores entre dos valores cualesquiera de una caracteristica).

Su gráfica es en forma de campana y simétrica respecto de un determinado parametro estadístico. Éste tipo de distribución propicia el modelado de numerosos fenómenos naturales, sociales y psicológicos. El centro de la campana es el promedio. La desviación estandar nos indican que tan dispersos o separados están los datos conr especto la media.

Para calcular la probabilidad normal se divide la cantidad de casos favorables entre la cantidad de datos totales, para ello se tuliza la siguiente fórmula: $$z=\dfrac{x-\mu}{\sigma} $$

De donde tenemos que $x$ es el valor de la condición y $\mu$ es el promedio también conocido como media y $\sigma$ es la desviación estandar. Manualmente podríamos calcularlo con las tablas de distribución normal.

Las funciones de densidad de probabilidad (de  variables aleatorias continuas) cumplen con las siguientes propiedades:

* El área bajo la curva de la función de densidad de probabilidad es igual a 1
* La probabilidad de que X se encuentre en determinado intervalo (a, b) es igual al área bajo la curva entre los puntos a y b.
* $P(X = c) = 0$ para cualquier valor c para el que se encuentre definida la función de densidad.

La funcion de densidad de probabilidad de una variable aleatoria $x$ que se distribuye como normal con media $\mu$ y desviacion estandar $\sigma$ es: $$f(x)=\dfrac{1}{\sigma\cdot\sqrt{2\pi}} e^{-{\dfrac{(x-\mu)^2}{(2\sigma)^2}}} $$ 

![Distribución normal](C:/users/Victor miguel terron/Documents/dnorm.png)

## DISTRIBUCIÓN $t$ DE STUDENT

La función de densidad $t$ de Student se define como:

En el caso de la distribución $t$ la media $\mu=0$ y $$\sigma^2=\dfrac{v}{(v-2)}$$ para $v>2$ respectivamente.

 La apariencia general de la distribución t es similar a la de la distribución normal estándar: ambas son simétricas y unimodales, y el valor máximo de la ordenada se alcanza en la media $\mu=0$. Sin embargo, la distribución $t$ tiene colas más amplias que la normal; esto es, la probabilidad de las colas es mayor que en la distribución normal. A medida que el número de grados de libertad tiende a infinito, la forma límite de la distribución $t$ es la distribución normal estándar.

### PROPIEDADES DE LA DISTRIBUCIÓN $t$ DE STUDENT

* Cada curva tiene forma de campana con centro en 0.
* Cada curva $t$ está más dispersa que la curva normal estandar $z$
* A medida que $v$ aumenta, la distribución de la curva $t$ correspondiente disminuye
* A medida que $v\rightarrow\infty$ la secuencia de curvas $t$ se aproxima a la curva normal estandar, por lo que la curva $z$ recibe a veces el nombre de curva $t$ con grados de libertad (gl)$gl=\infty$.

La distribución de la variable aleatoria $t$ está dada por:
$$f(t)=\dfrac{\Gamma\left(\dfrac{v+1}{2} \right)}{\Gamma\left(\dfrac{v}{2} \right)\cdot\sqrt{\pi v\sigma}}\cdot\left( 1+ \dfrac{1}{v} \left( \dfrac{x-\mu}{\sigma}  \right )^2 \right)^{-\dfrac{v+1}{2} } $$

De donde debemos recordar que $\sigma^2$ corresponde a varianza y no desviación estandar. Y que $v$ son los grados de libertad.

La formula de la varianza es: $$\sigma^2\cdot\dfrac{v}{v-2}$$, la moda es $=\mu$

![Densidad t de student con 7 GDL](C:/Users/Victor Miguel Terron/Documents/student7.png)

## TEOREMA DEL LÍMITE CENTRAL

Sean $y_1$, $y_2$,$…$, $y_n$ variables aleatorias independientes y distribuidas idénticamente con $E(y_i)= y$ $vy_i=2<\infty$. Definamos:
$$U_n=\dfrac{\sum_{i=1}^{n} y_i-n\mu}{\sigma\sqrt n}=\dfrac{\bar{y}-\mu}{\dfrac{\sigma}{\sqrt n}} $$

Entonces la función de distribución de $U_n$ converge hacia la función de distribución normal estándar cuando $n\rightarrow\infty$. Esto es:

$$P(U_n)=\int^{u}_{-\infty}\dfrac{1}{\sqrt{2\pi}}\cdot e^{\dfrac{-t^{2}}{2}} dt $$

Para toda $u$. Es decir que $\bar y$, está distribuida normalmente en forma asintótica con media $\mu$ y varianza $$\dfrac{\sigma^2 }{n} $$.

El teorema central del límite se puede aplciar a una muestra aleatoria $y_1$,$y_2$,$...$,$y_n$ para cualquier distribución mientras $E(y_i)=\mu$ y $V(y_i)=\sigma^2$ sean finitas y el tamaño muestral sea grande.


# ESTIMADORES PUNTUALES INSESGADOS COMUNES

__DEFINICIÓN__ Un estimador es una regla, a menudo expresada como una fórmula, que indica cómo calcular el valor de una estimación con base en las mediciones contenidas en una muestra.
![Definicion estimador insesgado comunes](C:/Users/Victor Miguel Terron/Documents/defini.png)

![valores esperados y errores estándar de algunos estimadores puntuales comunes](C:/users/Victor Miguel Terron/Documents/segundo.png)


# CONTRASTE DE HIPOTESIS

Los elementos de un contraste de hipotesis son:
* Hipótesis nula, H0
* Hipotesis alternativa, Ha
* Estadístico de prueba
* Región de rechazo

![Prueba de hipotesis](C:/Users/Victor Miguel Terron/Documents/tercero.png)
![Tipos de errores](C:/Users/Victor Miguel Terron/Documents/errores.png)


# CONTRASTES COMUNES CON MUESTRAS GRANDES

Suponga que deseamos contrastar un conjunto de hipótesis respecto a un parámetro con base a una muestra aleatoria $Y_1, Y_2, …, Y_n$. En esta sección desarrollaremos procedimientos de contrastes de hipótesis que están basados en un estimador que tiene una distribución muestral normal (aproximadamente) con media y error estándar .

Si 0 es un valor específico de, podemos probar H0: $\theta=0$ contra Ha: $\theta>0$. En este caso, las hipótesis nula y alternativa, el estadístico de prueba y la región de rechazo son como sigue:
![Conjunto de hipotesis](C:/Users/Victor Miguel Terron/Documents/contra.png)


![A](C:/Users/Victor Miguel Terron/Documents/lc.png)


# CONTRASTES DE HIPOTESIS DE NIVEL PARA MUESTRAS GRANDES


![B](C:/Users/Victor Miguel Terron/Documents/Contras.png)


¿Cómo decidir cuál hipótesis alternativa usar para una prueba? La respuesta depende de la hipótesis que pretendemos apoyar. Si estamos interesados sólo en detectar un aumento en el porcentaje de piezas defectuosas, por ejemplo, debemos localizar la región de rechazo en la cola superior de la distribución normal estándar. Por otra parte, si deseamos detectar un cambio en p ya sea arriba o debajo de p=0.10, debemos localizar la región de rechazo en ambas colas de la distribución normal estándar y emplear una prueba de dos colas.


![C](C:/Users/Victor Miguel Terron/Documents/after.png)

![D](C:/Users/Victor Miguel Terron/Documents/after1.png)

![E](C:/Users/Victor Miguel Terron/Documents/after2.png)

![F](C:/Users/Victor Miguel Terron/Documents/after3.png)



# WORK

Estudiar algunas distribuciones de probabilidad muy comunes y útiles, obtener estimaciones puntuales con propiedades deseables utilizando algunos estimadores insesgados comunes. Llevar a cabo contrastes de hipótesis que ayuden a tomar decisiones.

En esta sesión estudiaremos temas relacionados con los siguientes puntos:

* Cálculo de probabilidades y cuantiles de las distribuciones binomial, normal y t de Student
* Generación de muestras aleatorias de las distribuciones estudiadas
* Estudio del teorema central del límite mediante simulaciones
* Propiedades de algunos estimadores puntuales insesgados comunes
* Contraste de hipótesis con muestras grandes y pequeñas

## EJEMPLO 1 SESION 4. DISTRIBUCIONES BINOMIAL, NORMAL Y $T$ DE STUDENT

### OBJETIVO

* Aprender a obtener probabilidades, cuantiles y muestras aleatorias relacionadas con las distribuciones binomial, normal y t de Student
* Intepretar las probabilidades cuando se condieran las gráficas de las funciones de probabilidad y de densidad

### REQUISITOS

* Tener `R` y Rstudio instalados
* Haber leído el pre-work

### DESARROLLO

```{r DESARROLLO,comment=NA}
library(ggplot2) # Utilizaremos estos paquetes para algunas gráficas
library(reshape2)
```

# DISTRIBUCION BINOMIAL
En el caso de la __Distribución binomial__ En `R` para calcular valores de las funciones de probabilidad, distribución o cuantiles de la distribución binomial (discreta), usamos las funciones $dbinom$, $pbinom$ y $qbinom$ respectivamente. Para generar muestras aleatorias de esta distribución utilizamos la función $rbinom$.

Consideremos un experimento binomial con $n = 30$ pruebas idénticas e independientes, en donde la probabilidad de éxito en cada prueba es $p = 0.2$ (parámetros $n = 30$ y $p = 0.2$)
1. Suponga que realiza un examen de opción múltiple con 30 preguntas, en donde cada pregunta tiene 5 posibles respuestas, pero solo una es correcta siempre. Si elige la respuesta al azar en cada pregunta, y estamos interesados en el número de respuestas correctas obtenidas al final ¿Podemos decir que estamos ante un experimento binomial? 

## FUNCIÓN DE PROBABILIDAD
Para obtener P(X = 20), es decir, la probabilidad de observar 20 éxitos exactamente, en R ejecutamos:
```{r FPROB,comment=NA}
dbinom(x = 20, size = 30, prob = 0.2)

```
Para obtener P($x\leq20$), es decir, la probabilidad de observar a lo mucho 20 exitos o menos ejecutamos:
```{r pex,comment=NA,eval=FALSE}
pbinom(x<=20, size = 30, prob = 0.2)

```
La diferencia entre $dbinom()$ y $pbino()$ es que $dbinom()$ me dice cuál es la probabilidad de que $Pr(X=x)$ mientras que $pbinom()$ te calcula la probabilidad de que $Pr(X\leq x)$

Para encontrar el valor más pequeño b tal que P(X <= b) >= 0.35, es decir, el cuantil de orden 0.35, usamos:


## CUANTILES

```{r CUANTI,comment=NA,results='hold'}
qbinom(p = 0.35, size = 30, prob = 0.2) # b = 5

pbinom(q = 4, size = 30, prob = 0.2) # P(X <= 4) = 0.2552 < 0.35
pbinom(q = 5, size = 30, prob = 0.2) # P(X <= 5) = 0.4275 >= 0.35
pbinom(q = 6, size = 30, prob = 0.2) # P(X <= 6) = 0.6070 >= 0.35
```

## MUESTRAS ALEATORIAS

Para obtener una muestra aleatoria de tamaño $n = 1000$, de la distribución binomial con parámetros como especificamos, hacemos

```{r MUAL,comment=NA,results='hold'}
set.seed(4857) # Establecemos una semilla, 
# para poder reproducir la muestra en el futuro
muestra <- rbinom(n = 1000, size = 30, prob = 0.2)
length(muestra); muestra[1:3]
```

Podemos observar las frecuencias absolutas de los distintos valores obtenidos

```{r frecue,comment=NA,results='hold'}
as.data.frame(table(muestra))

```

También podemos observar las frecuencias relativas:
```{r frel,comment=NA,results='hold'}
(df1 <- as.data.frame(table(muestra)/length(muestra)))

valg <- as.character(df1$muestra) # distintos valores generados por rbinom
(valg <- as.numeric(valg)) # Convertimos a números
```

Las frecuencias relativas son muy parecidas a las siguientes probabilidades

```{r ch9,comment=NA,results='hold'}
(v1 <- round(sapply(valg, dbinom, size = 30, p = 0.2), 3))

```

Combinamos y unimos en un solo dataframe $df1$ y $v1$

```{r uni,comment=NA,results='hold'}

(df2 <- cbind(df1, v1))
(names(df2) <- c("Exitos", "FR", "Prob"))

(df2 <- melt(df2)) # función del paquete reshape2
```
Melt en cierta forma une los dataframes en uno solo pero basandose en ciertas condiciones

Las frecuencias relativas son muy parecidas a las probabilidades:

```{r frpp,comment=NA,results='hold'}
ggplot(df2, aes(x = Exitos, y = value, fill = variable)) + 
  geom_bar (stat="identity", position = "dodge")
# Funciones del paquete ggplot2
```

# DISTRIBUCIÓN NORMAL

En `R` para calcular valores de las funciones de densidad, distribución o cuantiles de la distribución normal (continua), usamos las funciones $dnorm$, $pnorm$ y $qnorm$ respectivamente. Para generar muestras aleatorias de esta distribución utilizamos la función $rnorm$.

Consideremos una variable aleatoria (v.a.) $X$ que se distribuye como normal con media 175 y desviación estándar 6 (parámetros mu = 175 y sigma = 6).

## FUNCIÓN DE DENSIDAD

La función de densidad sirve para caracterizar el comportamiento probable de una población en tanto especifíca la posibilidad relativa de que una variable aleatoria continuas $X$ tome un valor cercano a $x$.

Densidad significa que la suma de todas las areas del histograma deben ser igual a 1. La funcion de densidad es el contorno. Es una línea continua que representa la distribucion de densidad de TODA LA POBLACIÓN.

## FUNCION DE DISTRIBUCIÓN

La función de distribución asocia a cada valor de la variable alewatoria la probabilidad acumulada hasta ese valor, por ejemplo: Calcular la función de distribución de probabilidad de las puntuaciones obtenidas al lanzar un dado.

|    X   | $P_i$  |
|--------|--------|
|  $x<1$ |    0   |
|--------|--------|
|$$1\leq x <2$$|$$\dfrac{1}{6}$$|
|--------|--------|
|$$2\leq x <3$$|$$\dfrac{2}{6}$$|
|--------|--------|
|$$3\leq x <4$$|$$\dfrac{3}{6}$$|
|--------|--------|
|$$4\leq x <5$$|$$\dfrac{4}{6}$$|
|--------|--------|
|$$5\leq x <6$$|$$\dfrac{5}{6}$$|
|--------|--------|
|$$x \leq 6$$|$$1$$|



Siguiendo con el ejemplo disponible en el work tenemos lo siguiente:

Para obtener $P(x\leq 180)$, es decir, la probabilidad de que X tome un valor menor o igual a 180, ejecutamos:

```{r edwl,comment=NA}

x <- seq(-4, 4, 0.01)*6 + 175 # Algunos posibles 
# valores que puede tomar la v.a. 
# X (mínimo: mu-4sigma, máximo: mu+4sigma)
y <- dnorm(x, mean = 175, sd = 6) # Valores 
# correspondientes de la función de
# densidad de probabilidad
plot(x, y, type = "l", xlab = "", ylab = "")#Te grafica 
# en forma de campana los valores de x y y 
title(main = "Densidad de Probabilidad Normal",
      sub = expression(paste(mu == 175, " y ", sigma == 6)))#Agrega leyendas
#a gráfico
abline(v = 175, lwd = 2, lty = 2) # La media es 175 grafica la línea

pnorm(q = 180, mean = 175, sd = 6)

par(mfrow = c(2, 2))#ESTABLECE EL LIENZO EN EL PLOT PARA GRAFICAR 
#VARIAS EN UN MISMO ESPACIO
plot(x, y, type = "l",
     xlab = "",
     ylab = "")
#AGREGA LEYENDAS AL GRÁFICO
title(main = "Densidad de Probabilidad Normal",
      sub = expression(paste(mu == 175,
                             " y ",
                             sigma == 6)))
polygon(c(min(x), 
          x[x<=180],
          180),
        c(0, y[x<=180], 0),
        col="blue")#GRAFICA DENTRO DE LA DISTRIBUCIÓN
#LA PROBABILIDAD DE QUE X TOME VALORES MENORES A 180


#para obtener la probabilidad de que x P(x<=165), es decir, la probabilidad de
#que X tome un valor menor o igual a 165, ejecutamos:

pnorm(q = 165, mean = 175, sd = 6)
plot(x,y,type="l",
     xlab = "",
     ylab = "")
title(main = "Densidad de probabilidad normail",
      sub = expression(paste(mu==175,"y",sigma==6)))
polygon(c(min(x),
          x[x<=165],165),
        c(0,
          y[x<=165],0),
        col = "black")

#para obtener la probabilidad de que x P(x<=165), es decir, la probabilidad de
#que X tome un valor menor o igual a 165, ejecutamos:

pnorm(q = 165, mean = 175, sd = 6)
plot(x,y,type="l",
     xlab = "",
     ylab = "")
title(main = "Densidad de probabilidad normail",
      sub = expression(paste(mu==175,"y",sigma==6)))
polygon(c(min(x),
          x[x<=165],165),
        c(0,
          y[x<=165],0),
        col = "black")


```

Para obtener la probabilidad de que $P(165\leq X\leq180)$ ejecutamos el siguiente comando:
```{r pconj,comment=NA}
#PARA OBTENER P(165 <= X <= 180), es decir, la probabilidad de que X
#tome un valor mayor o igual a 165 y menor o igual a 180, debemos correr

pnorm(q = 180, mean = 175, sd = 6) - pnorm(q = 165, mean = 175, sd = 6)
plot(x,y,type="l",
     xlab = "",
     ylab = "")
title(main = "Densidad de probabilidad normail",
      sub = expression(paste(mu==175,"y",sigma==6)))
polygon(c(165,
          x[x>=165&x<=180],180),
        c(0,
          y[x>=165&x<=180],0),
        col = "yellow")

```

Para obtener $P(X\geq 182)$, es decir, la probabilidad de que X tome un valor mayor o igual a 182, una alternativa es:
```{r geq,comment=NA}
pnorm(q = 182, mean = 175, sd = 6, lower.tail = FALSE)
#graficando
plot(x,y,type="l",
     xlab = "",
     ylab = "")
title(main = "Densidad de probabilidad normail",
      sub = expression(paste(mu==175,"y",sigma==6)))

polygon(c(182,
          x[x>=182], max(x)),
        c(0,
          y[x>=182], 0),
        col="blue")

dev.off() # Para mostrar solo una gráfica
```

## CUANTILES 

Recordemos que los cuantiles ayudan a determinar porcentajes que superan o no un determinado valor de la variable.
Para encontrar el número $b$, tal que $P(X \leq b) = 0.75$, es decir, el cuantil de orden 0.75, ejecutamos:

```{r c75,comment=NA}
(b <- qnorm(p = 0.75, mean = 175, sd = 6)) 
#COMPROBANDO DE FORMA COMUN
pnorm(b, 175, 6)
# El cuantil se encuentra en el eje de medición (eje horizontal)
plot(x, y,
     type = "l",
     xlab="",
     ylab="")
title(main = "Densidad de Probabilidad Normal",
      sub = expression(paste(mu == 175, " y ", sigma == 6)))
#COLOCA UNA LÍNEA DONDE SE ENCUENTRA EL CUANTIL
axis(side = 1, at = b, font = 2, padj = 1, lwd = 2)
# SIDE un entero que especifica donde se colocará la linea
#1 abajo 2 izquierda 3 arriva 4 derecha
#AT es donde se colcoará la linea
#padj ajusta a cada linea, 0 es arriba o derecha, 1 es izq o inferior

```

## MUESTRAS ALEATORIAS

Para generar una muestra aleatoria de tamaño n = 1000 de la v.a. X corremos la siguiente instrucción

```{r mual,comment=NA}
set.seed(7563) # Para poder reproducir la muestra en el futuro
muestra <- rnorm(n = 1000, mean = 175, sd = 6)
length(muestra); mdf <- as.data.frame(muestra)
tail(mdf)
```

Observamos que el histograma de la muestra generada tiene forma de campana similar a la densidad de una normal

```{r hisatorial,comment=NA}
ggplot(mdf, aes(muestra)) + 
  geom_histogram(colour = 'red', 
                 fill = 'blue',
                 alpha = 0.3, # Intensidad del color fill
                 binwidth = 3) + 
  geom_density(aes(y = 3*..count..))+
  geom_vline(xintercept = mean(mdf$muestra), linetype="dashed", color = "black") + 
  ggtitle('Histograma para la muestra normal') + 
  labs(x = 'Valores obtenidos', y = 'Frecuencia')+
  theme_dark() +
  theme(plot.title = element_text(hjust = 0.5, size = 16))  
```

## REGLA EMPÍRICA

La regla empírica es una abreviatura utilizada para recordar el porcentaje de valores que se encuentran dentro de una banda alrededor de la media en una distribución normal con un ancho de dos, cuatro y seis veces la desviación típica, respectivamente.

```{r regempi,comment=NA,results='hide'}
mean <- 175; sd <- 6
x <- seq(mean-4*sd, mean+4*sd, 0.01)
y <- dnorm(x, mean, sd)
plot(x, y, type = "l",
     xlab="valores",
     ylab = "", 
     xaxt = "n",
     yaxt = "n")
title(main = "Densidad de Probabilidad Normal",
      sub = expression(paste("Regla Empírica con ",
                             mu == 175, 
                             " y ",
                             sigma == 6)))
abline(v=mean, lty = 2, lwd = 2)
for(k in c(-3, -2, -1, 1, 2, 3)) abline(v = mean+k*sd, lty = 2, col = abs(k))
ps <- c(mean - 3*sd, mean - 2*sd, 
        mean - sd, mean,
        mean + sd, 
        mean + 2*sd,
        mean + 3*sd)
axis(side = 1, at = ps)
x0 <- NULL
for(i in 1:length(ps)-1) x0 <- c(x0, (ps[i]+ps[i+1])/2)
y0 <- dnorm(x0, mean, sd)*1/3
text(x = x0, y = y0, labels = c("2.35%", "13.5%", "34%", "34%", "13.5%", "2.35%"))
x1 <- (x[1]+ps[1])/2; y1 <- dnorm(mean, mean, sd)*1/2
xf <- (x[length(x)]+ps[length(ps)])/2; yf <- dnorm(mean, mean, sd)*1/2
text(x = c(x1, xf), y = c(y1, yf), labels = c("0.15%", "0.15%"))
segments(x0 = x1, y0 = 0, x1 = x1, y1 = y1,               # Draw one line as in Example 1
         col = "cornflowerblue",                               # Color of line
         lwd = 5,                                              # Thickness of line
         lty = "dotted")     
segments(x0 = xf, y0 = 0, x1 = xf, y1 = yf,               
         col = "cornflowerblue",                               
         lwd = 5,                                              
         lty = "dotted")     
```


# DISTRIBUCIÓN t DE STUDENT 

En R para calcular valores de las funciones de densidad, distribución o cuantiles de la distribución t de Student (continua), usamos las funciones dt, pt y qt respectivamente. Para generar muestras aleatorias de esta distribución utilizamos la función rt.

Consideremos una variable aleatoria (v.a.) T que se distribuye como t de Student con 7 grados de libertad (gl) (parámetro gl = 7)

### FUNCIÓN DE DENSIDAD

```{r fdens,comment=NA}
x <- seq(-4, 4, 0.01) # Algunos valores que puede tomar la v.a. 
# T con 7 gl
y <- dt(x, df = 7) # Valores correspondientes de 
# la densidad t de Student con 7 gl
plot(x, y, type = "l", main = "Densidad t de Student, gl = 7", xlab="", ylab="")
abline(v = 0, lwd=2, lty=2)
```

Para encontrar P(T <= 1.5), ejecutamos la siguiente instrucción

```{r FDISTR,comment=NA}
pt(q = 1.5, df = 7)

```

Observemos la región que corresponde a esta probabilidad en la siguiente gráfica

```{r rco,comment=NA}
plot(x, y, 
     type = "l",
     main = "Densidad t de Student, gl = 7",
     xlab="",
     ylab="")
polygon(c(min(x),x[x<=1.5], 1.5),
        c(0, y[x<=1.5], 0),
        col="purple")
```

Para encontrar P(T >= 2), ejecutamos

```{r PT3,comment=NA}
pt(q = 2, df = 7, lower.tail = FALSE)

```

Observemos la región que corresponde a esta probabilidad en la siguiente gráfica


```{r observacione,comment=NA}
plot(x, y, type = "l",
     main = "Densidad t de Student, gl = 7",
     xlab="", ylab="")
polygon(c(2, x[x>=2], max(x)),
        c(0, y[x>=2], 0),
        col="orange")
```

## CUANTILES
Para encontrar el número d tal que P(T <= d) = 0.025, es decir, el cuantil de orden 0.025, corremos la siguiente instrucción

```{r CUANT,comment=NA}
(d <- qt(p = 0.025, df = 7))
#comprobando
pt(q = d, df = 7)
# Mostramos el cuantil encontrado en el eje de medición (eje horizontal)
plot(x, y, 
     type = "l",
     main = "Densidad t de Student, gl = 7",
     xlab="",
     ylab="")
axis(side = 1,
     at = d,
     font = 2,
     padj = 1,
     lwd = 2)

```

## MUESTRAS ALEATORIAS

Para generar una muestra aleatoria de tamaño n = 1000 de la v.a. T corremos la siguiente instrucción

```{r mAL2,comment=NA}
set.seed(777) # Para poder reproducir la muestra en el futuro
muestra <- rt(n = 1000, df = 7)
length(muestra); mdf <- as.data.frame(muestra)
tail(mdf)
```

Observamos que el histograma de la muestra generada tiene forma de campana similar a la densidad t de Student

```{r TSTUDENT,comment=NA}
ggplot(mdf, aes(muestra)) + 
  geom_histogram(colour = 'green', 
                 fill = 'orange',
                 alpha = 0.7, # Intensidad del color fill
                 binwidth = 0.5) + 
  geom_density(aes(y = 0.5*..count..))+
  geom_vline(xintercept = mean(mdf$muestra), linetype="dashed", color = "black") + 
  ggtitle('Histograma para la muestra t de Student') + 
  labs(x = 'Valores obtenidos', y = 'Frecuencia')+
  theme_light() +
  theme(plot.title = element_text(hjust = 0.5, size = 16))  
```

# ATENUAR COLORES

Para atenuar colores es necesario utilzar $alpha=0.8$ o la cantidad porcentual para atenuarse.

# RETO 1. DISTRIBUCIONES BINOMIAL, NORMAL Y T DE STUDENT
## OBJETIVO
* Calcular probabilidades y cuantiles relacionadas con algunas distribuciones de probabilidad útiles y comunes
* Generar muestras aleatorias que provengan de las distribuciones estudiadas

## REQUISITOS
* Haber trabajado con el Prework y el Work

## DESARROLLO 

### DISTRIBUCIÓN BINOMIAL 

Consideremos un experimento binomial con $n = 35$ pruebas idénticas e independientes, en donde la probabilidad de éxito en cada prueba es $p = 0.51$. Encuentre lo siguiente:

1. La probabilidad de observar exactamente 10 éxitos
2. La probabilidad de observar 10 o más exitos
3. El cuantil de orden 0.5
4. Genere una muestra aleatoria de tamaño 1000 de esta distribución, construya una tabla de frecuencias relativas con los resultados y realice el gráfico de barras de los resultados que muestre las frecuencias relativas.

### DISTRIBUCIÓN NORMAL

Considere una variable aleatoria normal con media 110 y desviación estándar 7. Realice lo siguiente:

1. Grafique la función de densidad de probabilidad
2. Encuentre la probabilidad de que la v.a. sea mayor o igual a 140
3. Encuentre el cuantil de orden 0.95
4. Genere una muestra aleatoria de tamaño 1000 y realice el histograma de frecuencias relativas para esta muestra

```{r ploteo,comment=NA}
#RETO 1 SESSION 4


##distribucion binomial
# Consideremos un experimento binomial con $n = 35$ pruebas idénticas e 
# independientes, en donde la probabilidad de éxito en cada prueba es 
# $p = 0.51$. Encuentre lo siguiente:
#   
# 1. La probabilidad de observar exactamente 10 éxitos
# 2. La probabilidad de observar 10 o más exitos
# 3. El cuantil de orden 0.5
# 4. Genere una muestra aleatoria de tamaño 1000 de esta
# distribución, construya una tabla de frecuencias relativas con los 
# resultados y realice el gráfico de barras de los resultados que 
# muestre las frecuencias relativas.

library(ggplot2)
#PUNTO 1
dbinom(x=10,size = 35,prob = 0.51)
#PUNTO 2
pbinom(q=9,size = 35,prob = 0.51,
       lower.tail = FALSE)
#PUNTO 3
qbinom(p = 0.5,size = 35,prob = 0.51)
# PUNTO 4
set.seed(123)
ale1000<- rbinom(n = 1000,size = 35,prob = 0.51)
class(ale1000)
ale1000dataaframe<-as.data.frame(table(ale1000)/length(ale1000))
head(ale1000dataaframe)
tail(ale1000dataaframe)
ggplot(ale1000dataaframe,
       aes(x = ale1000,y = Freq))+geom_bar(stat = "identity")



##DISTRIBUCION NORMAL
# Considere una variable aleatoria normal con media 110
#y desviación estándar 7. Realice lo siguiente:
# 1. Grafique la función de densidad de probabilidad
# 2. Encuentre la probabilidad de que la v.a. sea mayor o igual a 140
# 3. Encuentre el cuantil de orden 0.95
# 4. Genere una muestra aleatoria de tamaño 1000 y realice el histograma 
# de frecuencias relativas para esta muestra

#PUNTO 1

#GENERANDO LOS VALORES ALEATORIOS
vala1<- seq(10,100,by = 0.1)
View(vala1)
vala2<- dnorm(x = vala1,mean = 110,sd = 7)
class(vala1)
class(vala2)
df<-data.frame(vala1,vala2)
class(df)
View(df)
grafico<-ggplot(df,aes(vala1,vala2))+geom_line()


#PUNTO 2 PROBABILIDAD DE QUE VARIABLE ALEATORIA SEA MAYOR O IGUAL A 140
#LOWR TAIL SI ES VERDADERO LA PROBABILIDAD SERÁ P(X<=x) SI ES FALSO ES P(X>x)
pnorm(q = 140,mean = 110,sd = 7,lower.tail = FALSE)
#PUNTO 3. CUARTIL DE ORDEN 0.95
qnorm(p = 0.95,mean = 110,sd = 7)

#PUNTO 4.MUESTRA ALEATORIA DE TAMAÑO 1000 Y GENERE HISTOGRAMA DE FRECUENCIAS
set.seed(123)
datara<-rnorm(n = 1000,mean = 110,sd = 7)
dataradf<-as.data.frame(x = datara)
class(datara)
class(dataradf)
ggplot(data = dataradf,aes(datara))+
  geom_histogram(colour="blue",
                 fill="red",
                 alpha=0.6,
                 binwidth = 1.2)+
geom_density(aes(y=1.2*..count..))+
  geom_vline(xintercept = mean(datara),
             linetype="dashed", color = "black")+
  ggtitle(label = 'Histograma para la muestra normal')+
  labs(x='Valores obtenidos',y='Frecuencia')+
  theme_dark()+
  theme(plot.title = element_text(hjust = 0.5, size = 16))

```

# TEOREMA CENTRAL DEL LÍMITE

## OBJETIVO

* Comprender lo que afirma el teorema central del límite obteniendo muestras aleatorias de diferentes tamaños en R y observando la manera en la que se distribuyen las medias de las muestras generadas

## REQUISITOS

* Tener R y RStudio instalados
* Haber estudiado el Prework

##DESARROLLO

El teorema central del límite (TCL) es una teoría estadística que establece que, dada una muestra suficientemente grande de la población, la distribución de las medias muestrales seguirá una distribución normal.

Además, el TCL afirma que a medida que el tamaño de la muestra se incrementa, la media muestral se acercará a la media de la población. Por tanto, mediante el TCL podemos definir la distribución de la media muestral de una determinada población con una varianza conocida. De manera que la distribución seguirá una distribución normal si el tamaño de la muestra es lo suficientemente grande.

Cargamos el paquete ggplot2 para hacer algunas gráficas

